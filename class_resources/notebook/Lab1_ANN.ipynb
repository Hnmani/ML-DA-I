{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtPwM5am92wa",
        "outputId": "2944bea8-8379-43a4-e604-375cc0d991da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydantic 2.2.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.6.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "bT-0la7b-Kdb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "qbwvO4PV-Q3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Boston Housing dataset available within tensorflow\n",
        "(train_x, train_y),(test_x,test_y) = tf.keras.datasets.boston_housing.load_data(test_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id6HG0fN-Ob4",
        "outputId": "1b7e6a66-8ce0-4b32-c8dd-134391f84ae3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**"
      ],
      "metadata": {
        "id": "xVhBC6s7-Yym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Weights and Bias"
      ],
      "metadata": {
        "id": "EZp9Kt09-g-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We are initializing weights and Bias with Zero\n",
        "w = tf.zeros(shape=(13,1))\n",
        "b = tf.zeros(shape=(1))"
      ],
      "metadata": {
        "id": "mD7cvif9-V1U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to calculate prediction"
      ],
      "metadata": {
        "id": "Mik-QF_r-rTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(x, w, b):\n",
        "\n",
        "    xw_matmul = tf.matmul(x, w)\n",
        "    y = tf.add(xw_matmul, b)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "Nr_k0S6m-nyf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9unPoHoNEQzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to calculate loss"
      ],
      "metadata": {
        "id": "x-UB8jM0-xmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y_actual, y_predicted):\n",
        "\n",
        "    diff = y_actual - y_predicted\n",
        "    sqr = tf.square(diff)\n",
        "    avg = tf.reduce_mean(sqr)\n",
        "\n",
        "    return avg"
      ],
      "metadata": {
        "id": "rEM_yLbA-3Z7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to train the Model\n",
        "\n",
        "1.   Record all the mathematical steps to calculate Loss. We will record the steps using GradientTape\n",
        "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
        "3.   Update Weights and Bias based on gradients and learning rate"
      ],
      "metadata": {
        "id": "P18myY2d-64k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x, y_actual, w, b, learning_rate=0.01):\n",
        "\n",
        "    #Record mathematical operations on 'tape' to calculate loss\n",
        "    with tf.GradientTape() as t:\n",
        "\n",
        "        t.watch([w,b])\n",
        "\n",
        "        current_prediction = prediction(x, w, b)\n",
        "        current_loss = loss(y_actual, current_prediction)\n",
        "\n",
        "    #Calculate Gradients for Loss with respect to Weights and Bias\n",
        "    dw, db = t.gradient(current_loss,[w, b])\n",
        "\n",
        "    #Update Weights and Bias\n",
        "    w = w - learning_rate*dw\n",
        "    b = b - learning_rate*db\n",
        "\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "6Sdl9_a6_Dm8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start Training**"
      ],
      "metadata": {
        "id": "h0LqwZzw_ar1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.astype('float32')\n",
        "train_y = train_y.astype('float32')"
      ],
      "metadata": {
        "id": "qOHts05m_fFa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = tf.zeros(shape=(13,1))\n",
        "b = tf.zeros(shape=(1))\n",
        "#Train for 100 Steps\n",
        "for i in range(10):\n",
        "\n",
        "    w, b = train(train_x, train_y, w, b, learning_rate=0.000001)\n",
        "    print('Current Loss on iteration', i,\n",
        "          loss(train_y, prediction(train_x, w, b)).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jp99yGd_ifU",
        "outputId": "44beb7ef-eacf-451d-b663-7d59d47fed26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Loss on iteration 0 178.0955\n",
            "Current Loss on iteration 1 118.07554\n",
            "Current Loss on iteration 2 108.85365\n",
            "Current Loss on iteration 3 107.0173\n",
            "Current Loss on iteration 4 106.29444\n",
            "Current Loss on iteration 5 105.775154\n",
            "Current Loss on iteration 6 105.32404\n",
            "Current Loss on iteration 7 104.91794\n",
            "Current Loss on iteration 8 104.55014\n",
            "Current Loss on iteration 9 104.21671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Weights and Bias\n",
        "print('Weights:\\n', w.numpy())\n",
        "print('Bias:\\n',b.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiZKrEjA_npi",
        "outputId": "11902a28-db13-49dc-a4d2-886139aab399"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights:\n",
            " [[6.1097977e-05]\n",
            " [1.4757176e-03]\n",
            " [7.0035388e-04]\n",
            " [6.3028588e-06]\n",
            " [4.4483219e-05]\n",
            " [5.5957655e-04]\n",
            " [5.2818502e-03]\n",
            " [3.8869734e-04]\n",
            " [3.8556600e-04]\n",
            " [2.5673978e-02]\n",
            " [1.5497407e-03]\n",
            " [3.0143354e-02]\n",
            " [9.1384107e-04]]\n",
            "Bias:\n",
            " [8.7058805e-05]\n"
          ]
        }
      ]
    }
  ]
}